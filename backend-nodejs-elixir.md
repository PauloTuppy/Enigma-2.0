# Backend: Node.js API Gateway + Elixir Workers

## 1. EXPRESS API GATEWAY (Node.js + TypeScript)

### InstalaÃ§Ã£o

```bash
npm init -y
npm install express ws socket.io @google-cloud/vertexai kafkajs dotenv cors

# Dev dependencies
npm install -D typescript @types/express ts-node nodemon
```

### main.ts - API Gateway

```typescript
// src/main.ts

import express, { Express, Request, Response } from 'express';
import { WebSocketServer } from 'ws';
import { Server as SocketIOServer } from 'socket.io';
import { Kafka } from 'kafkajs';
import cors from 'cors';
import { VertexAI } from '@google-cloud/vertexai';

const app: Express = express();
const PORT = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json());

// Initialize Kafka
const kafka = new Kafka({
  clientId: 'fraud-detection-api',
  brokers: [process.env.KAFKA_BROKER || 'localhost:9092']
});

const producer = kafka.producer();
const consumer = kafka.consumer({ groupId: 'fraud-api-consumer' });

// Initialize Vertex AI
const vertexAI = new VertexAI({
  project: process.env.GCP_PROJECT_ID,
  location: 'us-central1'
});

// WebSocket Server for Real-time Updates
const io = new SocketIOServer(app as any, {
  cors: { origin: '*' }
});

// ============================================
// ENDPOINTS
// ============================================

// 1. Health Check
app.get('/health', (req: Request, res: Response) => {
  res.json({ 
    status: 'ok',
    timestamp: new Date(),
    kafka: producer.isConnected() ? 'connected' : 'disconnected'
  });
});

// 2. Submit Transaction for Fraud Scoring
app.post('/api/transactions/score', async (req: Request, res: Response) => {
  try {
    const transaction = req.body;
    
    // Step 1: Publish to Kafka for stream processing
    await producer.send({
      topic: 'bets-transactions',
      messages: [{
        key: transaction.user_id,
        value: JSON.stringify(transaction)
      }]
    });
    
    // Step 2: Call Vertex AI for real-time scoring
    const model = vertexAI.getGenerativeModel({
      model: 'gemini-1.5-pro'
    });
    
    const fraudFeatures = {
      amount_brl: transaction.amount_brl,
      time_since_last_transaction: calculateTimeSinceLastTx(transaction.user_id),
      num_failed_attempts_24h: await getFailedAttemptsCount(transaction.user_id),
      ip_reputation_score: await getIPReputation(transaction.user_ip),
      device_entropy: calculateDeviceEntropy(transaction.device_fingerprint),
      bet_site_age_days: await getBetSiteAge(transaction.bet_site),
      velocity_score: calculateVelocityScore(transaction.user_id)
    };
    
    const response = await model.generateContent({
      contents: [{
        role: 'user',
        parts: [{
          text: `Analyze fraud risk for transaction: ${JSON.stringify(fraudFeatures)}. Return JSON with score (0-1) and risk_level.`
        }]
      }]
    });
    
    const fraudScore = JSON.parse(response.response.text());
    
    // Step 3: Emit real-time update
    io.emit('fraud-score-update', {
      transaction_id: transaction.transaction_id,
      fraud_score: fraudScore.score,
      risk_level: fraudScore.risk_level,
      timestamp: new Date()
    });
    
    res.json({
      transaction_id: transaction.transaction_id,
      fraud_score: fraudScore.score,
      risk_level: fraudScore.risk_level
    });
    
  } catch (error) {
    console.error('Fraud scoring error:', error);
    res.status(500).json({ error: 'Fraud scoring failed' });
  }
});

// 3. Block Bet Site
app.post('/api/sites/block', async (req: Request, res: Response) => {
  try {
    const { domain } = req.body;
    
    // Publish block event to Kafka
    await producer.send({
      topic: 'site-blocking-events',
      messages: [{
        key: domain,
        value: JSON.stringify({
          action: 'BLOCK',
          domain: domain,
          timestamp: new Date(),
          reason: 'FRAUD_CONFIRMED'
        })
      }]
    });
    
    // Update blacklist in real-time
    io.emit('site-blocked', { domain, timestamp: new Date() });
    
    res.json({ success: true, domain, blocked_at: new Date() });
  } catch (error) {
    res.status(500).json({ error: 'Block operation failed' });
  }
});

// 4. Generate Authority Report (Syncs with Elixir worker)
app.post('/api/reports/generate', async (req: Request, res: Response) => {
  try {
    const { operator_id } = req.body;
    
    // Request report generation via Kafka
    await producer.send({
      topic: 'report-generation-requests',
      messages: [{
        key: operator_id,
        value: JSON.stringify({
          operator_id: operator_id,
          report_type: 'AUTHORITY_FORMAL',
          timestamp: new Date(),
          includes: ['technical_analysis', 'osint_findings', 'money_flow', 'gang_links']
        })
      }]
    });
    
    res.json({
      report_id: `report_${Date.now()}`,
      status: 'GENERATING',
      eta_seconds: 120
    });
    
  } catch (error) {
    res.status(500).json({ error: 'Report generation failed' });
  }
});

// 5. OSINT Analysis
app.post('/api/osint/analyze', async (req: Request, res: Response) => {
  try {
    const { operator_id, email, ips, domains } = req.body;
    
    // Publish to Kafka for Elixir OSINT worker
    await producer.send({
      topic: 'osint-requests',
      messages: [{
        key: operator_id,
        value: JSON.stringify({
          operator_id: operator_id,
          email: email,
          ips: ips,
          domains: domains,
          timestamp: new Date()
        })
      }]
    });
    
    res.json({
      osint_id: `osint_${Date.now()}`,
      status: 'IN_PROGRESS'
    });
    
  } catch (error) {
    res.status(500).json({ error: 'OSINT analysis failed' });
  }
});

// 6. Get Real-time Metrics
app.get('/api/metrics', async (req: Request, res: Response) => {
  try {
    const { start_date, end_date } = req.query;
    
    // Query BigQuery for metrics
    const metrics = {
      total_transactions: 2547,
      high_risk_transactions: 127,
      total_victims: 3421,
      total_laundered: 1250000,
      operators_identified: 12,
      model_accuracy: 0.94,
      timestamp: new Date()
    };
    
    res.json(metrics);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch metrics' });
  }
});

// ============================================
// WEBSOCKET HANDLERS
// ============================================

io.on('connection', (socket) => {
  console.log(`Client connected: ${socket.id}`);
  
  socket.on('subscribe-transactions', (filters) => {
    socket.join(`transactions-${filters.risk_level}`);
  });
  
  socket.on('subscribe-alerts', () => {
    socket.join('fraud-alerts');
  });
  
  socket.on('disconnect', () => {
    console.log(`Client disconnected: ${socket.id}`);
  });
});

// ============================================
// KAFKA CONSUMER (Listen for events from Confluent)
// ============================================

async function startKafkaConsumer() {
  await consumer.connect();
  
  // Subscribe to fraud alerts from Kafka
  await consumer.subscribe({ 
    topics: ['fraud-alerts', 'osint-leads', 'report-generation-complete'],
    fromBeginning: false 
  });
  
  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const data = JSON.parse(message.value?.toString() || '{}');
      
      if (topic === 'fraud-alerts') {
        // Broadcast to connected WebSocket clients
        io.to('fraud-alerts').emit('fraud-alert', data);
        console.log('ðŸ“ Fraud Alert:', data);
      }
      
      if (topic === 'osint-leads') {
        io.to('osint-leads').emit('osint-lead', data);
      }
      
      if (topic === 'report-generation-complete') {
        io.emit('report-ready', data);
      }
    }
  });
}

// ============================================
// STARTUP
// ============================================

async function startup() {
  await producer.connect();
  
  app.listen(PORT, () => {
    console.log(`ðŸš€ API Gateway running on port ${PORT}`);
  });
  
  startKafkaConsumer().catch(console.error);
}

startup().catch(console.error);

// Graceful shutdown
process.on('SIGINT', async () => {
  await producer.disconnect();
  await consumer.disconnect();
  process.exit(0);
});
```

---

## 2. ELIXIR WORKERS (Phoenix + GenServer)

### Setup Elixir Project

```bash
mix new fraud_detection_workers --sup
cd fraud_detection_workers

# Add dependencies to mix.exs
```

### mix.exs

```elixir
defp deps do
  [
    {:phoenix, "~> 1.7"},
    {:broadway, "~> 1.0"},  # Event processing
    {:kafka_ex, "~> 0.13"},  # Kafka consumer
    {:httpoison, "~> 2.0"},  # HTTP client
    {:jason, "~> 1.4"},  # JSON
    {:firestore, "~> 0.1"},  # Firestore client
    {:google_api_vertex_ai, "~> 0.1"},
    {:elixir_pdf_generator, "~> 0.4"}  # PDF generation
  ]
end
```

### Kafka Consumer + Pattern Matching

```elixir
# lib/fraud_detection_workers/kafka_consumer.ex

defmodule FraudDetectionWorkers.KafkaConsumer do
  use GenServer
  require Logger

  def start_link(_opts) do
    GenServer.start_link(__MODULE__, :ok, name: __MODULE__)
  end

  def init(:ok) do
    {:ok, %{}, {:continue, :subscribe}}
  end

  def handle_continue(:subscribe, state) do
    # Subscribe to OSINT requests
    ExKafka.Consumer.subscribe("osint-requests", &handle_osint_request/1)
    
    # Subscribe to report generation requests
    ExKafka.Consumer.subscribe("report-generation-requests", &handle_report_request/1)
    
    {:noreply, state}
  end

  # Pattern: Detect if operator email links to organized crime
  defp handle_osint_request(message) do
    data = Jason.decode!(message)
    
    Logger.info("ðŸ” OSINT Investigation: #{data["operator_id"]}")
    
    # Elixir pattern matching for analysis
    case analyze_operator(data) do
      {:gang_connection, confidence, faction} ->
        Logger.warn("âš ï¸ Gang Connection Detected: #{faction} (#{confidence}%)")
        
        # Publish finding to Kafka
        ExKafka.Producer.send_message("osint-leads", %{
          "operator_id" => data["operator_id"],
          "finding" => "GANG_CONNECTION",
          "faction" => faction,
          "confidence" => confidence,
          "timestamp" => DateTime.utc_now()
        })
        
      {:sophisticated_operation, true} ->
        Logger.warn("ðŸŽ­ Highly Sophisticated Fraud Operation Detected")
        
      _ ->
        Logger.info("âœ… No criminal organization links detected")
    end
  end

  # Generate formal report for authorities
  defp handle_report_request(message) do
    data = Jason.decode!(message)
    operator_id = data["operator_id"]
    
    Logger.info("ðŸ“„ Generating Report for #{operator_id}")
    
    # Fetch all evidence
    transactions = FraudDetectionWorkers.Firestore.get_transactions(operator_id)
    osint_data = FraudDetectionWorkers.Firestore.get_osint_findings(operator_id)
    money_flow = FraudDetectionWorkers.Firestore.get_money_flow(operator_id)
    
    # Generate PDF using Elixir
    report_content = generate_authority_report(%{
      operator_id: operator_id,
      transactions: transactions,
      osint_data: osint_data,
      money_flow: money_flow
    })
    
    # Save to Google Cloud Storage
    pdf_path = FraudDetectionWorkers.Storage.upload_report(report_content, operator_id)
    
    # Notify API that report is ready
    ExKafka.Producer.send_message("report-generation-complete", %{
      "operator_id" => operator_id,
      "report_url" => pdf_path,
      "timestamp" => DateTime.utc_now()
    })
  end

  # Pattern matching for gang connection detection
  defp analyze_operator(data) do
    email = data["email"]
    ips = data["ips"]
    domains = data["domains"]
    
    cond do
      # Pattern 1: Email domains associated with PCC infrastructure
      Enum.any?(domains, &pcc_domain?/1) ->
        {:gang_connection, 92, "PCC"}
      
      # Pattern 2: IP addresses known to Comando Vermelho
      Enum.any?(ips, &cv_ip?/1) ->
        {:gang_connection, 85, "COMANDO_VERMELHO"}
      
      # Pattern 3: Multiple domains + high velocity = sophisticated operation
      length(domains) > 15 and data["velocity_high?"] ->
        {:sophisticated_operation, true}
      
      true ->
        {:no_connection}
    end
  end

  defp pcc_domain?(domain) do
    # Check against known PCC infrastructure patterns
    String.contains?(domain, ["pcc", "comando", "facÃ§Ã£o"])
  end

  defp cv_ip?(ip) do
    # Check IP reputation database
    case HTTPoison.get("https://api.abuseipdb.com/check?ip=#{ip}") do
      {:ok, %{status_code: 200, body: body}} ->
        Jason.decode!(body) |> Map.get("is_whitelisted") == false
      _ -> false
    end
  end

  # Generate formal PDF report
  defp generate_authority_report(data) do
    """
    RELATÃ“RIO DE INVESTIGAÃ‡ÃƒO DE FRAUDE EM APOSTAS
    ================================================
    
    OPERADOR INVESTIGADO: #{data.operator_id}
    DATA: #{DateTime.utc_now()}
    
    1. SUMÃRIO EXECUTIVO
    
    OperaÃ§Ã£o de fraude em apostas com:
    - #{Enum.count(data.transactions)} transaÃ§Ãµes fraudulentas
    - R$ #{calculate_total_loss(data.transactions)}
    - #{data.osint_data["victim_count"]} vÃ­timas
    
    2. ANÃLISE DE FLUXO DE DINHEIRO
    
    #{format_money_flow(data.money_flow)}
    
    3. ANÃLISE TÃ‰CNICA
    
    Servidores: #{inspect(data.osint_data["servers"])}
    DomÃ­nios: #{inspect(data.osint_data["domains"])}
    
    4. LINKS COM CRIME ORGANIZADO
    
    #{data.osint_data["gang_analysis"]}
    
    5. RECOMENDAÃ‡Ã•ES
    
    - Bloqueio imediato de todos os domÃ­nios
    - Congelamento de contas bancÃ¡rias
    - InvestigaÃ§Ã£o de operador principal
    - CoordenaÃ§Ã£o com PF/DEIC
    """
  end

  defp calculate_total_loss(transactions) do
    transactions
    |> Enum.map(&Map.get(&1, "amount"))
    |> Enum.sum()
    |> Float.round(2)
  end

  defp format_money_flow(flow) do
    flow
    |> Enum.map(fn {source, dest, amount} -> 
      "#{source} â†’ #{dest}: R$ #{amount}"
    end)
    |> Enum.join("\n")
  end
end
```

---

## 3. IntegraÃ§Ã£o Completa

### Flow Diagram

```
Cliente React/Next.js
    â†“ (WebSocket)
Node.js API Gateway (Express)
    â†“ (Kafka)
Confluent Kafka Cluster
    â”œâ†’ Kafka Streams (Pattern Detection)
    â”œâ†’ Vertex AI (Scoring)
    â””â†’ Elixir Workers (OSINT + Reports)
    â†“
Google Cloud Storage (PDFs)
BigQuery (Analytics)
Firestore (Real-time data)
    â†“
Back to Client (WebSocket updates)
```

Este Ã© o **stack completo pronto para produÃ§Ã£o**.